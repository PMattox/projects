{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b62b48",
   "metadata": {},
   "source": [
    "# Wordle Source Parsing\n",
    "\n",
    "Digging into the Wordle web page to find the latest lists of solutions and acceptable plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa9225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ccfc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# grab the entire html and store as a variable\n",
    "wordle_url = 'https://www.nytimes.com/games-assets/v2/wordle.6b88b1c8c6541b07820ab0896f6bc19be0ae34b2.js'\n",
    "html_text = requests.get(wordle_url).text\n",
    "# soup = BeautifulSoup(html_text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c7e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33928273",
   "metadata": {},
   "source": [
    "## List of Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5c6554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"cigar\",\"rebut\",\"sissy\",\"humph\",\"awake\",\"blush\",\"focal\",\"evade\",\"naval\",\"serve\",\"heath\",\"dwarf\",\"model\",\"karma\",\"stink\",\"grade\",\"quiet\",\"bench\",\"abate\",\"feign\",\"major\",\"death\",\"fresh\",\"crust\",\"stool\",\"colon\",\"abase\",\"marry\",\"react\",\"batty\",\"pride\",\"floss\",\"helix\",\"croak\",\"staff\",\"paper\",\"unfed\",\"whelp\",\"trawl\",\"outdo\",\"adobe\",\"crazy\",\"sower\",\"repay\",\"digit\",\"crate\",\"cluck\",\"spike\",\"mimic\",\"pound\",\"maxim\",\"linen\",\"unmet\",\"flesh\",\"booby\",\"forth\",\"first\",\"stand\",\"belly\",\"ivory\",\"seedy\",\"print\",\"yearn\",\"drain\",\"bribe\",\"stout\",\"panel\",\"crass\",\"flume\",\"offal\",\"agree\",\"error\",\"swirl\",\"argue\",\"bleed\",\"delta\",\"flick\",\"totem\",\"wooer\",\"front\",\"shrub\",\"parry\",\"biome\",\"lapel\",\"start\",\"greet\",\"goner\",\"golem\",\"lusty\",\"loopy\",\"round\",\"audit\",\"lying\",\"gamma\",\"labor\",\"islet\",\"civic\",\"forge\",\"corny\",\"moult\",\"basic\",\"salad\",\"agate\",\"spicy\",\"spray\",\"essay\",\"fjord\",\"spend\",\"kebab\",\"guild\",\"aback\",\"motor\",\"alone\",\"hatch\",\"hyper\",\"thumb\",\"dowry\",\"ought\",\"belch\",\"dutch\",\"pilot\",\"tweed\",\"comet\",\"jaunt\",\"enema\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the starting point of the \"J\" list of words\n",
    "soln_list_s_loc = html_text.find(\"J=\")+2\n",
    "soln_list_s_loc\n",
    "\n",
    "# find the ending point of the \"J\" list of words\n",
    "soln_list_e_loc = html_text.find(\"]\",soln_list_s_loc)+1\n",
    "soln_list_e_loc\n",
    "\n",
    "# subset the overall file based on the start and end locations\n",
    "soln_string = html_text[soln_list_s_loc:soln_list_e_loc]\n",
    "# examine the first 1000 characters of this new string variable\n",
    "soln_string[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da547f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'re\",\"payer\",\"sooth\",\"unset\",\"unlit\",\"vomit\",\"fanny\",\"fetus\",\"butch\",\"stalk\",\"flack\",\"widow\",\"augur\"]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the end of this same string variable\n",
    "soln_string[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb44ba5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['unset',\n",
       " 'unlit',\n",
       " 'vomit',\n",
       " 'fanny',\n",
       " 'fetus',\n",
       " 'butch',\n",
       " 'stalk',\n",
       " 'flack',\n",
       " 'widow',\n",
       " 'augur']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to a list\n",
    "import ast \n",
    "\n",
    "soln_list = ast.literal_eval(soln_string)\n",
    "print(type(soln_list))\n",
    "print(len(soln_list))\n",
    "# view a few of the later entries in this new list\n",
    "#   we should see a prettier version of the output above this cell\n",
    "soln_list[len(soln_list)-10:len(soln_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed3a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a file\n",
    "\n",
    "# sort list alphabetically\n",
    "soln_list.sort()\n",
    "\n",
    "# create DataFrame\n",
    "hr_df = pd.DataFrame(soln_list)\n",
    "\n",
    "# add column name\n",
    "hr_df.columns = ['word']\n",
    "\n",
    "# export to csv format\n",
    "hr_df.to_csv('wordle_solutions.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6d23d5",
   "metadata": {},
   "source": [
    "## List of Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee530eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"aahed\",\"aalii\",\"aargh\",\"aarti\",\"abaca\",\"abaci\",\"abacs\",\"abaft\",\"abaka\",\"abamp\",\"aband\",\"abash\",\"abask\",\"abaya\",\"abbas\",\"abbed\",\"abbes\",\"abcee\",\"abeam\",\"abear\",\"abele\",\"abers\",\"abets\",\"abies\",\"abler\",\"ables\",\"ablet\",\"ablow\",\"abmho\",\"abohm\",\"aboil\",\"aboma\",\"aboon\",\"abord\",\"abore\",\"abram\",\"abray\",\"abrim\",\"abrin\",\"abris\",\"absey\",\"absit\",\"abuna\",\"abune\",\"abuts\",\"abuzz\",\"abyes\",\"abysm\",\"acais\",\"acari\",\"accas\",\"accoy\",\"acerb\",\"acers\",\"aceta\",\"achar\",\"ached\",\"aches\",\"achoo\",\"acids\",\"acidy\",\"acing\",\"acini\",\"ackee\",\"acker\",\"acmes\",\"acmic\",\"acned\",\"acnes\",\"acock\",\"acold\",\"acred\",\"acres\",\"acros\",\"acted\",\"actin\",\"acton\",\"acyls\",\"adaws\",\"adays\",\"adbot\",\"addax\",\"added\",\"adder\",\"addio\",\"addle\",\"adeem\",\"adhan\",\"adieu\",\"adios\",\"adits\",\"adman\",\"admen\",\"admix\",\"adobo\",\"adown\",\"adoze\",\"adrad\",\"adred\",\"adsum\",\"aduki\",\"adunc\",\"adust\",\"advew\",\"adyta\",\"adzed\",\"adzes\",\"aecia\",\"aedes\",\"aegis\",\"aeons\",\"aerie\",\"aeros\",\"aesir\",\"afald\",\"afara\",\"afars\",\"afear\",\"aflaj\",\"afore\",\"afrit\",\"afros\",\"agama\",\"agami\",\"agars\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the starting point of the \"J\" list of words\n",
    "play_list_s_loc = html_text.find(\"Q=\")+2\n",
    "play_list_s_loc\n",
    "\n",
    "# find the ending point of the \"J\" list of words\n",
    "play_list_e_loc = html_text.find(\"]\",play_list_s_loc)+1\n",
    "play_list_e_loc\n",
    "\n",
    "# subset the overall file based on the start and end locations\n",
    "play_string = html_text[play_list_s_loc:play_list_e_loc]\n",
    "play_string[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd510f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "10665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aahed',\n",
       " 'aalii',\n",
       " 'aargh',\n",
       " 'aarti',\n",
       " 'abaca',\n",
       " 'abaci',\n",
       " 'abacs',\n",
       " 'abaft',\n",
       " 'abaka',\n",
       " 'abamp',\n",
       " 'aband',\n",
       " 'abash',\n",
       " 'abask',\n",
       " 'abaya',\n",
       " 'abbas']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to list as we did with the other collection of words (above)\n",
    "\n",
    "play_list = ast.literal_eval(play_string)\n",
    "print(type(play_list))\n",
    "print(len(play_list))\n",
    "play_list[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5496f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a file\n",
    "\n",
    "# sort list alphabetically\n",
    "play_list.sort()\n",
    "\n",
    "# create DataFrame\n",
    "hr_df = pd.DataFrame(play_list)\n",
    "\n",
    "# add column name\n",
    "hr_df.columns = ['word']\n",
    "\n",
    "# export to csv format\n",
    "hr_df.to_csv('wordle_plays.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33eaec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5f910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3cf44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82bf4d99",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://www.geeksforgeeks.org/python-convert-a-string-representation-of-list-into-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb4729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
